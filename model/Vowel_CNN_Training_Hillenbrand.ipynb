{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8340489",
   "metadata": {},
   "source": [
    "# ğŸ¤ OIIAIOIIIAI å…ƒéŸ³è¯†åˆ« CNN è®­ç»ƒ (Vowel Dataset)\n",
    "\n",
    "æœ¬ notebook ä½¿ç”¨ **Dataset of Vowels** è®­ç»ƒå…ƒéŸ³è¯†åˆ«æ¨¡å‹ã€‚\n",
    "\n",
    "## ä¸ºä»€ä¹ˆæ¢æ•°æ®é›†ï¼Ÿ\n",
    "\n",
    "ä¹‹å‰ä½¿ç”¨ TIMIT æ•°æ®é›†çš„é—®é¢˜ï¼š\n",
    "- TIMIT ä¸­çš„å…ƒéŸ³è¢«è¾…éŸ³åŒ…å›´ï¼ˆå¦‚ \"bat\", \"bet\"ï¼‰ï¼Œå­˜åœ¨**ååŒå‘éŸ³æ•ˆåº”**\n",
    "- æ¨¡å‹å­¦åˆ°çš„æ˜¯ã€Œè¾…éŸ³-å…ƒéŸ³-è¾…éŸ³ã€çš„è¿‡æ¸¡ç‰¹å¾ï¼Œè€Œéçº¯å…ƒéŸ³ç‰¹å¾\n",
    "- éªŒè¯é›†å‡†ç¡®ç‡ 92%ï¼Œä½†åœ¨çœŸå®çš„çº¯å…ƒéŸ³è¾“å…¥ï¼ˆæ¸¸æˆåœºæ™¯ï¼‰è¡¨ç°å¾ˆå·®\n",
    "\n",
    "## Dataset of Vowels æ•°æ®é›†\n",
    "\n",
    "- æ¥æºï¼šKaggle `darubiano57/dataset-of-vowels`\n",
    "- åŒ…å« **16875 ä¸ªå­¤ç«‹å…ƒéŸ³å½•éŸ³** (a/e/i/o/u)\n",
    "- ç”·æ€§ (h) å’Œå¥³æ€§ (m) è¯´è¯è€…\n",
    "- æ–‡ä»¶åæ ¼å¼ï¼š`{æ€§åˆ«}{å…ƒéŸ³}_{è¯´è¯è€…ID}_ ({åºå·}).wav`\n",
    "\n",
    "## æ•°æ®é¢„å¤„ç†\n",
    "\n",
    "åŸå§‹æ•°æ®å­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼Œéœ€è¦é¢„å¤„ç†ï¼š\n",
    "1. **é•¿åº¦ä¸ä¸€**ï¼š50ms ~ 2sï¼Œéœ€è¦æ£€æµ‹æœ‰æ•ˆå‘éŸ³åŒºåŸŸ\n",
    "2. **å»¶è¿Ÿå‘éŸ³**ï¼šå½•éŸ³å¼€å§‹åæ‰å‘éŸ³ï¼Œéœ€è¦ç”¨èƒ½é‡æ£€æµ‹å®šä½\n",
    "3. **éŸ³é‡ä¸ä¸€**ï¼šéœ€è¦å½’ä¸€åŒ–\n",
    "4. **ç¯å¢ƒå™ªå£°**ï¼šå¯ä½œä¸ºæ•°æ®å¢å¼ºçš„ä¸€éƒ¨åˆ†\n",
    "\n",
    "## æ•°æ®å¢å¼ºç­–ç•¥\n",
    "\n",
    "1. éšæœºæ‹¼æ¥ 2-4 ä¸ªå…ƒéŸ³ç‰‡æ®µï¼Œæ¨¡æ‹Ÿ \"OIIAIOIIIAI\" å¼çš„è¿ç»­è¾“å…¥\n",
    "2. æ·»åŠ èƒŒæ™¯å™ªå£°ï¼ˆç™½å™ªå£°ã€ç²‰å™ªå£°ï¼‰\n",
    "3. åº”ç”¨éŸ³é‡å˜åŒ–ã€è½»å¾®æ—¶ç§»\n",
    "4. ä»æ‹¼æ¥åºåˆ—ä¸­æå– 210ms çª—å£ä½œä¸ºè®­ç»ƒæ ·æœ¬\n",
    "\n",
    "## æ¨¡å‹è§„æ ¼\n",
    "- **è¾“å…¥**: 210ms åŸå§‹æ³¢å½¢ (3360 samples @ 16kHz)\n",
    "- **è¾“å‡º**: 6 ç±» (A/E/I/O/U/silence)\n",
    "- **æ ¼å¼**: TensorFlow.jsï¼Œå¯ç›´æ¥åœ¨æµè§ˆå™¨è¿è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f470e1",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒé…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸…ç†ä¹‹å‰çš„è®­ç»ƒç›®å½•ï¼ˆå¦‚éœ€è¦ï¼‰\n",
    "!rm -rf /content/vowel_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f511a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŒ‚è½½ Google Driveï¼ˆç”¨äºä¿å­˜è¾“å‡ºï¼‰\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„åŒ…ï¼ˆä»…æ‰§è¡Œä¸€æ¬¡ï¼‰\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def is_installed(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "packages_to_check = ['tensorflowjs', 'soundfile', 'kagglehub']\n",
    "need_install = not all(is_installed(pkg.replace('-', '_')) for pkg in packages_to_check)\n",
    "\n",
    "if need_install:\n",
    "    # å®‰è£… kagglehubï¼ˆæ–°çš„ Kaggle æ•°æ®é›†ä¸‹è½½æ–¹å¼ï¼‰\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'kagglehub'], capture_output=True)\n",
    "    subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'soundfile', 'tensorflowjs'], capture_output=True)\n",
    "    print(\"âœ… åŒ…å®‰è£…å®Œæˆ\")\n",
    "else:\n",
    "    print(\"âœ… åŒ…å·²å®‰è£…ï¼Œè·³è¿‡\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861f888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"\\nTensorFlow ç‰ˆæœ¬: {tf.__version__}\")\n",
    "print(f\"GPU å¯ç”¨: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ GPU\n",
    "!nvidia-smi\n",
    "\n",
    "import tensorflow as tf\n",
    "print(f\"\\nTensorFlow ç‰ˆæœ¬: {tf.__version__}\")\n",
    "print(f\"GPU å¯ç”¨: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3d1de",
   "metadata": {},
   "source": [
    "## 2. ä¸‹è½½ Dataset of Vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "\n",
    "# ä¸‹è½½æ•°æ®é›†\n",
    "print(\"æ­£åœ¨ä¸‹è½½ Dataset of Vowels...\")\n",
    "dataset_path = kagglehub.dataset_download(\"darubiano57/dataset-of-vowels\")\n",
    "print(f\"âœ… æ•°æ®é›†å·²ä¸‹è½½åˆ°: {dataset_path}\")\n",
    "\n",
    "# æŸ¥æ‰¾å®é™…çš„æ•°æ®ç›®å½•\n",
    "# æ•°æ®é›†ç»“æ„ï¼šDATASET_OF_VOWELS ç›®å½•ä¸‹æœ‰ wav æ–‡ä»¶\n",
    "vowel_data_dir = os.path.join(dataset_path, 'DATASET_OF_VOWELS')\n",
    "if not os.path.exists(vowel_data_dir):\n",
    "    # å¦‚æœæ²¡æœ‰å­ç›®å½•ï¼Œå¯èƒ½ç›´æ¥åœ¨æ ¹ç›®å½•\n",
    "    vowel_data_dir = dataset_path\n",
    "\n",
    "print(f\"\\næ•°æ®ç›®å½•: {vowel_data_dir}\")\n",
    "\n",
    "# ç»Ÿè®¡æ–‡ä»¶\n",
    "import glob\n",
    "wav_files = glob.glob(os.path.join(vowel_data_dir, '*.wav'))\n",
    "print(f\"æ‰¾åˆ° {len(wav_files)} ä¸ª wav æ–‡ä»¶\")\n",
    "\n",
    "# æ˜¾ç¤ºä¸€äº›æ–‡ä»¶åç¤ºä¾‹\n",
    "print(\"\\næ–‡ä»¶åç¤ºä¾‹:\")\n",
    "for f in wav_files[:10]:\n",
    "    print(f\"  {os.path.basename(f)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e484759",
   "metadata": {},
   "source": [
    "## 3. é…ç½®å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc6b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# ============ æ•°æ®è·¯å¾„ï¼ˆç”±ä¸Šä¸€æ­¥è‡ªåŠ¨è®¾ç½®ï¼‰ ============\n",
    "VOWEL_DATA_DIR = vowel_data_dir\n",
    "# =====================================================\n",
    "\n",
    "# å·¥ä½œç›®å½•\n",
    "WORK_DIR = '/content/vowel_training'\n",
    "DATA_DIR = os.path.join(WORK_DIR, 'data')\n",
    "CHECKPOINT_DIR = os.path.join(WORK_DIR, 'checkpoints')\n",
    "OUTPUT_DIR = os.path.join(WORK_DIR, 'output')\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# éŸ³é¢‘å‚æ•°ï¼ˆä¸ TIMIT ç‰ˆæœ¬ä¿æŒä¸€è‡´ï¼‰\n",
    "SAMPLE_RATE = 16000           # 16kHz é‡‡æ ·ç‡\n",
    "FRAME_LENGTH = 400            # 25ms å¸§é•¿\n",
    "FRAME_STEP = 160              # 10ms å¸§ç§»\n",
    "FFT_LENGTH = 512              # FFT ç‚¹æ•°\n",
    "N_MELS = 40                   # Mel é¢‘å¸¦æ•°\n",
    "INPUT_SAMPLES = 3360          # 210ms @ 16kHz\n",
    "\n",
    "# å…ƒéŸ³ç±»åˆ«\n",
    "VOWEL_CLASSES = ['A', 'E', 'I', 'O', 'U', 'silence']\n",
    "NUM_CLASSES = len(VOWEL_CLASSES)\n",
    "\n",
    "# æ–‡ä»¶åæ ¼å¼: {æ€§åˆ«}{å…ƒéŸ³}_{è¯´è¯è€…ID}_ ({åºå·}).wav\n",
    "# ä¾‹å¦‚: ho_1_ (80).wav = ç”·æ€§(h) + Oå…ƒéŸ³ + è¯´è¯è€…1 + ç¬¬80ä¸ªæ ·æœ¬\n",
    "# å…ƒéŸ³å­—æ¯æ˜ å°„ï¼ˆå°å†™ -> å¤§å†™ï¼‰\n",
    "VOWEL_LETTER_MAP = {\n",
    "    'a': 'A',\n",
    "    'e': 'E',\n",
    "    'i': 'I',\n",
    "    'o': 'O',\n",
    "    'u': 'U',\n",
    "}\n",
    "\n",
    "# è®­ç»ƒé…ç½®\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "\n",
    "# æ•°æ®å¢å¼ºé…ç½®\n",
    "AUGMENT_CONFIG = {\n",
    "    'concat_min_vowels': 2,      # æœ€å°‘æ‹¼æ¥å…ƒéŸ³æ•°\n",
    "    'concat_max_vowels': 4,      # æœ€å¤šæ‹¼æ¥å…ƒéŸ³æ•°\n",
    "    'noise_prob': 0.5,           # æ·»åŠ å™ªå£°çš„æ¦‚ç‡\n",
    "    'noise_level_range': (0.001, 0.01),  # å™ªå£°å¼ºåº¦èŒƒå›´\n",
    "    'volume_range': (0.7, 1.3),  # éŸ³é‡å˜åŒ–èŒƒå›´\n",
    "    'samples_per_vowel': 500,    # æ¯ä¸ªå…ƒéŸ³ç”Ÿæˆçš„æ ·æœ¬æ•°\n",
    "}\n",
    "\n",
    "# éŸ³é¢‘é¢„å¤„ç†é…ç½®ï¼ˆé’ˆå¯¹æ•°æ®è´¨é‡é—®é¢˜ï¼‰\n",
    "PREPROCESS_CONFIG = {\n",
    "    'energy_threshold': 0.01,    # èƒ½é‡é˜ˆå€¼ï¼ˆç”¨äºæ£€æµ‹å‘éŸ³å¼€å§‹/ç»“æŸï¼‰\n",
    "    'min_vowel_duration': 0.05,  # æœ€å°æœ‰æ•ˆå…ƒéŸ³æ—¶é•¿ (50ms)\n",
    "    'max_vowel_duration': 1.0,   # æœ€å¤§æˆªå–æ—¶é•¿ (1s)\n",
    "    'onset_window_ms': 10,       # èƒ½é‡æ£€æµ‹çª—å£å¤§å° (ms)\n",
    "    'onset_hop_ms': 5,           # èƒ½é‡æ£€æµ‹æ­¥é•¿ (ms)\n",
    "}\n",
    "\n",
    "print(\"âœ… é…ç½®å®Œæˆ!\")\n",
    "print(f\"   æ•°æ®è·¯å¾„: {VOWEL_DATA_DIR}\")\n",
    "print(f\"   è¾“å‡ºç›®å½•: {OUTPUT_DIR}\")\n",
    "print(f\"   è¾“å…¥é•¿åº¦: {INPUT_SAMPLES} samples ({INPUT_SAMPLES/SAMPLE_RATE*1000:.0f}ms)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98da410a",
   "metadata": {},
   "source": [
    "## 4. åŠ è½½å¹¶é¢„å¤„ç†æ•°æ®\n",
    "\n",
    "å…³é”®é¢„å¤„ç†æ­¥éª¤ï¼š\n",
    "1. **èƒ½é‡æ£€æµ‹**ï¼šæ‰¾åˆ°éŸ³é¢‘ä¸­å®é™…å‘éŸ³çš„èµ·å§‹å’Œç»“æŸä½ç½®\n",
    "2. **æœ‰æ•ˆåŒºåŸŸæˆªå–**ï¼šåªä¿ç•™æœ‰å£°éŸ³çš„éƒ¨åˆ†\n",
    "3. **éŸ³é‡å½’ä¸€åŒ–**ï¼šç»Ÿä¸€éŸ³é‡æ°´å¹³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6798af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def load_audio_file(filepath, target_sr=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(filepath, sr=target_sr, mono=True)\n",
    "        return audio\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            audio, sr = sf.read(filepath)\n",
    "            if len(audio.shape) > 1:\n",
    "                audio = audio.mean(axis=1)  # è½¬å•å£°é“\n",
    "            if sr != target_sr:\n",
    "                audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
    "            return audio.astype(np.float32)\n",
    "        except Exception as e2:\n",
    "            print(f\"âš ï¸ æ— æ³•åŠ è½½: {filepath}, é”™è¯¯: {e2}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def parse_vowel_filename(filename):\n",
    "    \"\"\"\n",
    "    ä»æ–‡ä»¶åè§£æå…ƒéŸ³ç±»å‹å’Œè¯´è¯è€…ä¿¡æ¯\n",
    "    \n",
    "    æ–‡ä»¶åæ ¼å¼: {æ€§åˆ«}{å…ƒéŸ³}_{è¯´è¯è€…ID}_ ({åºå·}).wav\n",
    "    ä¾‹å¦‚: ho_1_ (80).wav = ç”·æ€§(h) + Oå…ƒéŸ³ + è¯´è¯è€…1 + ç¬¬80ä¸ªæ ·æœ¬\n",
    "          ma_2_ (19).wav = å¥³æ€§(m) + Aå…ƒéŸ³ + è¯´è¯è€…2 + ç¬¬19ä¸ªæ ·æœ¬\n",
    "    \n",
    "    Returns:\n",
    "        vowel_class: 'A', 'E', 'I', 'O', 'U' æˆ– None\n",
    "        speaker: è¯´è¯è€…æ ‡è¯† (å¦‚ 'h1', 'm2')\n",
    "        gender: 'male' æˆ– 'female'\n",
    "    \"\"\"\n",
    "    basename = os.path.splitext(filename)[0].lower()\n",
    "    \n",
    "    # åŒ¹é…æ¨¡å¼: {hæˆ–m}{a/e/i/o/u}_{æ•°å­—}_ ({æ•°å­—})\n",
    "    match = re.match(r'^([hm])([aeiou])_(\\d+)_\\s*\\((\\d+)\\)$', basename)\n",
    "    \n",
    "    if not match:\n",
    "        return None, None, None\n",
    "    \n",
    "    gender_code = match.group(1)\n",
    "    vowel_letter = match.group(2)\n",
    "    speaker_id = match.group(3)\n",
    "    \n",
    "    gender = 'male' if gender_code == 'h' else 'female'\n",
    "    speaker = f\"{gender_code}{speaker_id}\"\n",
    "    \n",
    "    vowel_class = VOWEL_LETTER_MAP.get(vowel_letter)\n",
    "    \n",
    "    return vowel_class, speaker, gender\n",
    "\n",
    "\n",
    "def detect_voice_activity(audio, sr=SAMPLE_RATE, \n",
    "                          window_ms=10, hop_ms=5, \n",
    "                          energy_threshold=0.01):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨çŸ­æ—¶èƒ½é‡æ£€æµ‹è¯­éŸ³æ´»åŠ¨åŒºåŸŸ\n",
    "    \n",
    "    Args:\n",
    "        audio: éŸ³é¢‘æ•°æ®\n",
    "        sr: é‡‡æ ·ç‡\n",
    "        window_ms: çª—å£å¤§å°ï¼ˆæ¯«ç§’ï¼‰\n",
    "        hop_ms: æ­¥é•¿ï¼ˆæ¯«ç§’ï¼‰\n",
    "        energy_threshold: èƒ½é‡é˜ˆå€¼ï¼ˆç›¸å¯¹äºæœ€å¤§èƒ½é‡çš„æ¯”ä¾‹ï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        start_sample: è¯­éŸ³å¼€å§‹çš„é‡‡æ ·ç‚¹\n",
    "        end_sample: è¯­éŸ³ç»“æŸçš„é‡‡æ ·ç‚¹\n",
    "    \"\"\"\n",
    "    window_samples = int(sr * window_ms / 1000)\n",
    "    hop_samples = int(sr * hop_ms / 1000)\n",
    "    \n",
    "    # è®¡ç®—çŸ­æ—¶èƒ½é‡\n",
    "    energies = []\n",
    "    for i in range(0, len(audio) - window_samples, hop_samples):\n",
    "        frame = audio[i:i + window_samples]\n",
    "        energy = np.sum(frame ** 2) / window_samples\n",
    "        energies.append(energy)\n",
    "    \n",
    "    if not energies:\n",
    "        return 0, len(audio)\n",
    "    \n",
    "    energies = np.array(energies)\n",
    "    max_energy = np.max(energies)\n",
    "    \n",
    "    if max_energy == 0:\n",
    "        return 0, len(audio)\n",
    "    \n",
    "    # å½’ä¸€åŒ–èƒ½é‡\n",
    "    norm_energies = energies / max_energy\n",
    "    \n",
    "    # æ‰¾åˆ°è¶…è¿‡é˜ˆå€¼çš„åŒºåŸŸ\n",
    "    active_frames = norm_energies > energy_threshold\n",
    "    \n",
    "    if not np.any(active_frames):\n",
    "        return 0, len(audio)\n",
    "    \n",
    "    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªæ´»åŠ¨å¸§\n",
    "    active_indices = np.where(active_frames)[0]\n",
    "    first_active = active_indices[0]\n",
    "    last_active = active_indices[-1]\n",
    "    \n",
    "    # è½¬æ¢å›é‡‡æ ·ç‚¹\n",
    "    start_sample = first_active * hop_samples\n",
    "    end_sample = min((last_active + 1) * hop_samples + window_samples, len(audio))\n",
    "    \n",
    "    return start_sample, end_sample\n",
    "\n",
    "\n",
    "def preprocess_vowel_audio(audio, sr=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    é¢„å¤„ç†å…ƒéŸ³éŸ³é¢‘ï¼š\n",
    "    1. æ£€æµ‹è¯­éŸ³æ´»åŠ¨åŒºåŸŸ\n",
    "    2. æˆªå–æœ‰æ•ˆéƒ¨åˆ†\n",
    "    3. å½’ä¸€åŒ–éŸ³é‡\n",
    "    \n",
    "    Returns:\n",
    "        processed_audio: å¤„ç†åçš„éŸ³é¢‘ï¼Œå¦‚æœæ— æ•ˆè¿”å› None\n",
    "    \"\"\"\n",
    "    if audio is None or len(audio) == 0:\n",
    "        return None\n",
    "    \n",
    "    # æ£€æµ‹è¯­éŸ³æ´»åŠ¨\n",
    "    start, end = detect_voice_activity(\n",
    "        audio, sr,\n",
    "        window_ms=PREPROCESS_CONFIG['onset_window_ms'],\n",
    "        hop_ms=PREPROCESS_CONFIG['onset_hop_ms'],\n",
    "        energy_threshold=PREPROCESS_CONFIG['energy_threshold']\n",
    "    )\n",
    "    \n",
    "    # æˆªå–æœ‰æ•ˆåŒºåŸŸ\n",
    "    active_audio = audio[start:end]\n",
    "    \n",
    "    # æ£€æŸ¥æœ€å°æ—¶é•¿\n",
    "    min_samples = int(sr * PREPROCESS_CONFIG['min_vowel_duration'])\n",
    "    if len(active_audio) < min_samples:\n",
    "        return None\n",
    "    \n",
    "    # é™åˆ¶æœ€å¤§æ—¶é•¿\n",
    "    max_samples = int(sr * PREPROCESS_CONFIG['max_vowel_duration'])\n",
    "    if len(active_audio) > max_samples:\n",
    "        # å–ä¸­é—´éƒ¨åˆ†\n",
    "        excess = len(active_audio) - max_samples\n",
    "        start_offset = excess // 2\n",
    "        active_audio = active_audio[start_offset:start_offset + max_samples]\n",
    "    \n",
    "    # å½’ä¸€åŒ–éŸ³é‡\n",
    "    max_val = np.max(np.abs(active_audio))\n",
    "    if max_val > 0:\n",
    "        active_audio = active_audio / max_val * 0.9\n",
    "    \n",
    "    return active_audio.astype(np.float32)\n",
    "\n",
    "\n",
    "def load_vowel_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    åŠ è½½å¹¶é¢„å¤„ç†æ‰€æœ‰å…ƒéŸ³æ ·æœ¬\n",
    "    \n",
    "    Returns:\n",
    "        vowel_bank: dict, {vowel_class: [{'audio': ..., 'speaker': ..., 'gender': ...}, ...]}\n",
    "    \"\"\"\n",
    "    vowel_bank = defaultdict(list)\n",
    "    \n",
    "    # æŸ¥æ‰¾æ‰€æœ‰ wav æ–‡ä»¶\n",
    "    wav_files = glob.glob(os.path.join(data_dir, '*.wav'))\n",
    "    \n",
    "    print(f\"æ‰¾åˆ° {len(wav_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶\")\n",
    "    \n",
    "    # ç»Ÿè®¡\n",
    "    stats = {\n",
    "        'total': 0,\n",
    "        'parsed': 0,\n",
    "        'loaded': 0,\n",
    "        'valid': 0,\n",
    "        'by_vowel': defaultdict(int),\n",
    "        'by_gender': defaultdict(int),\n",
    "        'skipped_reasons': defaultdict(int),\n",
    "    }\n",
    "    \n",
    "    for filepath in tqdm(wav_files, desc=\"åŠ è½½éŸ³é¢‘\"):\n",
    "        stats['total'] += 1\n",
    "        filename = os.path.basename(filepath)\n",
    "        \n",
    "        # è§£ææ–‡ä»¶å\n",
    "        vowel_class, speaker, gender = parse_vowel_filename(filename)\n",
    "        \n",
    "        if vowel_class is None:\n",
    "            stats['skipped_reasons']['parse_failed'] += 1\n",
    "            continue\n",
    "        stats['parsed'] += 1\n",
    "        \n",
    "        # åŠ è½½éŸ³é¢‘\n",
    "        audio = load_audio_file(filepath)\n",
    "        if audio is None:\n",
    "            stats['skipped_reasons']['load_failed'] += 1\n",
    "            continue\n",
    "        stats['loaded'] += 1\n",
    "        \n",
    "        # é¢„å¤„ç†\n",
    "        processed = preprocess_vowel_audio(audio)\n",
    "        if processed is None:\n",
    "            stats['skipped_reasons']['too_short'] += 1\n",
    "            continue\n",
    "        stats['valid'] += 1\n",
    "        \n",
    "        # ä¿å­˜\n",
    "        vowel_bank[vowel_class].append({\n",
    "            'audio': processed,\n",
    "            'speaker': speaker,\n",
    "            'gender': gender,\n",
    "            'filepath': filepath\n",
    "        })\n",
    "        \n",
    "        stats['by_vowel'][vowel_class] += 1\n",
    "        stats['by_gender'][gender] += 1\n",
    "    \n",
    "    # æ‰“å°ç»Ÿè®¡\n",
    "    print(f\"\\nå¤„ç†ç»Ÿè®¡:\")\n",
    "    print(f\"  æ€»æ–‡ä»¶æ•°: {stats['total']}\")\n",
    "    print(f\"  è§£ææˆåŠŸ: {stats['parsed']}\")\n",
    "    print(f\"  åŠ è½½æˆåŠŸ: {stats['loaded']}\")\n",
    "    print(f\"  æœ‰æ•ˆæ ·æœ¬: {stats['valid']}\")\n",
    "    print(f\"\\nè·³è¿‡åŸå› :\")\n",
    "    for reason, count in stats['skipped_reasons'].items():\n",
    "        print(f\"  {reason}: {count}\")\n",
    "    print(f\"\\næ€§åˆ«åˆ†å¸ƒ:\")\n",
    "    for gender, count in stats['by_gender'].items():\n",
    "        print(f\"  {gender}: {count}\")\n",
    "    \n",
    "    return vowel_bank\n",
    "\n",
    "\n",
    "print(\"å‡½æ•°å®šä¹‰å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d1ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ•°æ®é›†\n",
    "print(\"=\"*60)\n",
    "print(\"åŠ è½½ Dataset of Vowels\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "vowel_bank = load_vowel_dataset(VOWEL_DATA_DIR)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"åŠ è½½ç»“æœ:\")\n",
    "print(\"-\"*40)\n",
    "total = 0\n",
    "for vowel in VOWEL_CLASSES[:-1]:  # æ’é™¤ silence\n",
    "    count = len(vowel_bank.get(vowel, []))\n",
    "    print(f\"  {vowel}: {count} ä¸ªæœ‰æ•ˆæ ·æœ¬\")\n",
    "    total += count\n",
    "print(\"-\"*40)\n",
    "print(f\"  æ€»è®¡: {total} ä¸ªæœ‰æ•ˆæ ·æœ¬\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8fc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ä¸€äº›æ ·æœ¬ï¼ŒéªŒè¯é¢„å¤„ç†æ•ˆæœ\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"é¢„å¤„ç†æ•ˆæœå¯è§†åŒ–\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "fig, axes = plt.subplots(5, 4, figsize=(16, 12))\n",
    "\n",
    "for row_idx, vowel in enumerate(['A', 'E', 'I', 'O', 'U']):\n",
    "    samples = vowel_bank.get(vowel, [])\n",
    "    if not samples:\n",
    "        continue\n",
    "    \n",
    "    # éšæœºé€‰4ä¸ªæ ·æœ¬\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(len(samples), min(4, len(samples)), replace=False)\n",
    "    \n",
    "    for col_idx, idx in enumerate(indices):\n",
    "        sample = samples[idx]\n",
    "        audio = sample['audio']\n",
    "        speaker = sample['speaker']\n",
    "        \n",
    "        ax = axes[row_idx, col_idx]\n",
    "        \n",
    "        # ç»˜åˆ¶æ³¢å½¢\n",
    "        time_axis = np.arange(len(audio)) / SAMPLE_RATE * 1000  # æ¯«ç§’\n",
    "        ax.plot(time_axis, audio, linewidth=0.5)\n",
    "        ax.set_title(f\"{vowel} - {speaker} ({len(audio)/SAMPLE_RATE*1000:.0f}ms)\")\n",
    "        ax.set_xlabel('Time (ms)')\n",
    "        ax.set_ylabel('Amplitude')\n",
    "        ax.set_ylim(-1, 1)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'preprocessed_samples.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ç»Ÿè®¡å¤„ç†åçš„éŸ³é¢‘é•¿åº¦åˆ†å¸ƒ\n",
    "print(\"\\nå¤„ç†åéŸ³é¢‘é•¿åº¦åˆ†å¸ƒ:\")\n",
    "all_lengths = []\n",
    "for vowel in VOWEL_CLASSES[:-1]:\n",
    "    for sample in vowel_bank.get(vowel, []):\n",
    "        all_lengths.append(len(sample['audio']) / SAMPLE_RATE * 1000)\n",
    "\n",
    "if all_lengths:\n",
    "    all_lengths = np.array(all_lengths)\n",
    "    print(f\"  æœ€çŸ­: {np.min(all_lengths):.0f}ms\")\n",
    "    print(f\"  æœ€é•¿: {np.max(all_lengths):.0f}ms\")\n",
    "    print(f\"  å¹³å‡: {np.mean(all_lengths):.0f}ms\")\n",
    "    print(f\"  ä¸­ä½æ•°: {np.median(all_lengths):.0f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bc007f",
   "metadata": {},
   "source": [
    "## 5. æ•°æ®å¢å¼ºï¼šå…ƒéŸ³æ‹¼æ¥ + å™ªå£°å åŠ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe520ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(length, noise_type='white'):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆå™ªå£°ä¿¡å·\n",
    "    \n",
    "    Args:\n",
    "        length: æ ·æœ¬é•¿åº¦\n",
    "        noise_type: 'white' æˆ– 'pink'\n",
    "    \"\"\"\n",
    "    if noise_type == 'white':\n",
    "        return np.random.randn(length).astype(np.float32)\n",
    "    elif noise_type == 'pink':\n",
    "        # ç®€å•çš„ç²‰å™ªå£°ç”Ÿæˆï¼ˆ1/f å™ªå£°ï¼‰\n",
    "        white = np.random.randn(length)\n",
    "        fft = np.fft.rfft(white)\n",
    "        freqs = np.fft.rfftfreq(length)\n",
    "        freqs[0] = 1  # é¿å…é™¤ä»¥é›¶\n",
    "        fft = fft / np.sqrt(freqs)\n",
    "        pink = np.fft.irfft(fft, n=length)\n",
    "        return pink.astype(np.float32)\n",
    "    else:\n",
    "        return np.zeros(length, dtype=np.float32)\n",
    "\n",
    "\n",
    "def generate_silence_sample(length=INPUT_SAMPLES, noise_level=0.001):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆé™éŸ³æ ·æœ¬ï¼ˆå¸¦è½»å¾®èƒŒæ™¯å™ªå£°ï¼‰\n",
    "    \"\"\"\n",
    "    noise_type = np.random.choice(['white', 'pink'])\n",
    "    noise = generate_noise(length, noise_type)\n",
    "    noise = noise / (np.max(np.abs(noise)) + 1e-8) * noise_level\n",
    "    return noise\n",
    "\n",
    "\n",
    "def get_random_vowel_segment(vowel_bank, vowel_class, min_len, max_len):\n",
    "    \"\"\"\n",
    "    ä»å…ƒéŸ³åº“ä¸­éšæœºè·å–ä¸€ä¸ªæŒ‡å®šé•¿åº¦çš„ç‰‡æ®µ\n",
    "    \"\"\"\n",
    "    samples = vowel_bank.get(vowel_class, [])\n",
    "    if not samples:\n",
    "        return None\n",
    "    \n",
    "    # éšæœºé€‰æ‹©ä¸€ä¸ªæ ·æœ¬\n",
    "    sample_info = np.random.choice(samples)\n",
    "    audio = sample_info['audio'].copy()\n",
    "    \n",
    "    # ç¡®å®šæˆªå–é•¿åº¦\n",
    "    if len(audio) <= min_len:\n",
    "        # éŸ³é¢‘å¤ªçŸ­ï¼Œç›´æ¥ä½¿ç”¨å…¨éƒ¨\n",
    "        segment = audio\n",
    "    else:\n",
    "        # éšæœºé€‰æ‹©é•¿åº¦å’Œèµ·å§‹ä½ç½®\n",
    "        actual_max = min(max_len, len(audio))\n",
    "        if actual_max <= min_len:\n",
    "            segment_len = len(audio)\n",
    "        else:\n",
    "            segment_len = np.random.randint(min_len, actual_max)\n",
    "        \n",
    "        max_start = len(audio) - segment_len\n",
    "        start_idx = np.random.randint(0, max(1, max_start + 1))\n",
    "        segment = audio[start_idx:start_idx + segment_len]\n",
    "    \n",
    "    return segment\n",
    "\n",
    "\n",
    "def concatenate_vowels(vowel_bank, num_vowels=3, crossfade_samples=160):\n",
    "    \"\"\"\n",
    "    éšæœºé€‰æ‹©å¹¶æ‹¼æ¥å¤šä¸ªå…ƒéŸ³\n",
    "    \n",
    "    Args:\n",
    "        vowel_bank: å…ƒéŸ³æ ·æœ¬åº“\n",
    "        num_vowels: æ‹¼æ¥çš„å…ƒéŸ³æ•°é‡\n",
    "        crossfade_samples: äº¤å‰æ·¡åŒ–çš„æ ·æœ¬æ•°ï¼ˆ10ms @ 16kHzï¼‰\n",
    "    \n",
    "    Returns:\n",
    "        concatenated: æ‹¼æ¥åçš„éŸ³é¢‘\n",
    "        vowel_sequence: å…ƒéŸ³åºåˆ—æ ‡ç­¾ [(start, end, vowel_class), ...]\n",
    "    \"\"\"\n",
    "    available_vowels = [v for v in VOWEL_CLASSES[:-1] if v in vowel_bank and len(vowel_bank[v]) > 0]\n",
    "    \n",
    "    if len(available_vowels) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # éšæœºé€‰æ‹©å…ƒéŸ³åºåˆ—\n",
    "    vowel_sequence = np.random.choice(available_vowels, num_vowels)\n",
    "    \n",
    "    segments = []\n",
    "    labels = []\n",
    "    current_pos = 0\n",
    "    \n",
    "    # æ¯ä¸ªç‰‡æ®µçš„é•¿åº¦èŒƒå›´\n",
    "    min_len = INPUT_SAMPLES // 2  # 105ms\n",
    "    max_len = INPUT_SAMPLES * 2   # 420ms\n",
    "    \n",
    "    for vowel in vowel_sequence:\n",
    "        segment = get_random_vowel_segment(vowel_bank, vowel, min_len, max_len)\n",
    "        \n",
    "        if segment is None or len(segment) == 0:\n",
    "            continue\n",
    "        \n",
    "        # åº”ç”¨éŸ³é‡å˜åŒ–\n",
    "        volume_factor = np.random.uniform(*AUGMENT_CONFIG['volume_range'])\n",
    "        segment = segment * volume_factor\n",
    "        \n",
    "        # è®°å½•æ ‡ç­¾\n",
    "        labels.append({\n",
    "            'start': current_pos,\n",
    "            'end': current_pos + len(segment),\n",
    "            'vowel': vowel\n",
    "        })\n",
    "        \n",
    "        segments.append(segment)\n",
    "        current_pos += len(segment) - crossfade_samples  # é‡å éƒ¨åˆ†\n",
    "    \n",
    "    if len(segments) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    # æ‹¼æ¥ï¼ˆå¸¦äº¤å‰æ·¡åŒ–ï¼‰\n",
    "    total_length = sum(len(s) for s in segments) - crossfade_samples * (len(segments) - 1)\n",
    "    if total_length <= 0:\n",
    "        return None, None\n",
    "        \n",
    "    concatenated = np.zeros(total_length, dtype=np.float32)\n",
    "    \n",
    "    pos = 0\n",
    "    for i, segment in enumerate(segments):\n",
    "        if i == 0:\n",
    "            end_pos = min(pos + len(segment), total_length)\n",
    "            concatenated[pos:end_pos] = segment[:end_pos - pos]\n",
    "        else:\n",
    "            # äº¤å‰æ·¡åŒ–\n",
    "            fade_len = min(crossfade_samples, len(segment), total_length - pos)\n",
    "            if fade_len > 0:\n",
    "                fade_in = np.linspace(0, 1, fade_len)\n",
    "                fade_out = np.linspace(1, 0, fade_len)\n",
    "                \n",
    "                # æ·¡å‡ºå‰ä¸€æ®µçš„å°¾éƒ¨\n",
    "                concatenated[pos:pos + fade_len] *= fade_out\n",
    "                # å åŠ å½“å‰æ®µï¼ˆæ·¡å…¥å¼€å¤´ï¼‰\n",
    "                segment_copy = segment.copy()\n",
    "                segment_copy[:fade_len] *= fade_in\n",
    "                \n",
    "                end_pos = min(pos + len(segment_copy), total_length)\n",
    "                copy_len = end_pos - pos\n",
    "                concatenated[pos:end_pos] += segment_copy[:copy_len]\n",
    "        \n",
    "        pos += len(segment) - crossfade_samples\n",
    "    \n",
    "    return concatenated, labels\n",
    "\n",
    "\n",
    "def extract_training_sample(audio, labels, sample_length=INPUT_SAMPLES):\n",
    "    \"\"\"\n",
    "    ä»æ‹¼æ¥åçš„éŸ³é¢‘ä¸­æå–è®­ç»ƒæ ·æœ¬\n",
    "    \n",
    "    Returns:\n",
    "        sample: éŸ³é¢‘ç‰‡æ®µ\n",
    "        label: ä¸»è¦å…ƒéŸ³æ ‡ç­¾ï¼ˆå æ¯”æœ€å¤§çš„ï¼‰\n",
    "    \"\"\"\n",
    "    if len(audio) < sample_length:\n",
    "        # å¡«å……\n",
    "        padded = np.zeros(sample_length, dtype=np.float32)\n",
    "        start = (sample_length - len(audio)) // 2\n",
    "        padded[start:start + len(audio)] = audio\n",
    "        audio = padded\n",
    "        # è°ƒæ•´æ ‡ç­¾ä½ç½®\n",
    "        for l in labels:\n",
    "            l['start'] += start\n",
    "            l['end'] += start\n",
    "    \n",
    "    # éšæœºé€‰æ‹©èµ·å§‹ä½ç½®\n",
    "    max_start = len(audio) - sample_length\n",
    "    if max_start <= 0:\n",
    "        start_idx = 0\n",
    "    else:\n",
    "        start_idx = np.random.randint(0, max_start)\n",
    "    \n",
    "    end_idx = start_idx + sample_length\n",
    "    sample = audio[start_idx:end_idx]\n",
    "    \n",
    "    # ç¡®å®šä¸»è¦æ ‡ç­¾ï¼ˆçª—å£å†…å æ¯”æœ€å¤§çš„å…ƒéŸ³ï¼‰\n",
    "    vowel_coverage = defaultdict(int)\n",
    "    for l in labels:\n",
    "        overlap_start = max(start_idx, l['start'])\n",
    "        overlap_end = min(end_idx, l['end'])\n",
    "        if overlap_end > overlap_start:\n",
    "            vowel_coverage[l['vowel']] += overlap_end - overlap_start\n",
    "    \n",
    "    if vowel_coverage:\n",
    "        label = max(vowel_coverage, key=vowel_coverage.get)\n",
    "    else:\n",
    "        label = 'silence'\n",
    "    \n",
    "    return sample, label\n",
    "\n",
    "\n",
    "def add_noise(audio, noise_level):\n",
    "    \"\"\"\n",
    "    æ·»åŠ èƒŒæ™¯å™ªå£°\n",
    "    \"\"\"\n",
    "    noise_type = np.random.choice(['white', 'pink'])\n",
    "    noise = generate_noise(len(audio), noise_type)\n",
    "    noise = noise / (np.max(np.abs(noise)) + 1e-8) * noise_level\n",
    "    \n",
    "    return audio + noise\n",
    "\n",
    "\n",
    "print(\"æ•°æ®å¢å¼ºå‡½æ•°å®šä¹‰å®Œæˆ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆå¢å¼ºåçš„è®­ç»ƒæ•°æ®\n",
    "print(\"=\"*60)\n",
    "print(\"ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼ˆæ‹¼æ¥ + å™ªå£°å¢å¼ºï¼‰\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "generated_samples = defaultdict(list)\n",
    "samples_per_vowel = AUGMENT_CONFIG['samples_per_vowel']\n",
    "\n",
    "# ä¸ºæ¯ä¸ªå…ƒéŸ³ç±»åˆ«ç”Ÿæˆæ ·æœ¬\n",
    "for target_vowel in tqdm(VOWEL_CLASSES[:-1], desc=\"ç”Ÿæˆæ ·æœ¬\"):\n",
    "    count = 0\n",
    "    attempts = 0\n",
    "    max_attempts = samples_per_vowel * 10\n",
    "    \n",
    "    while count < samples_per_vowel and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        \n",
    "        # éšæœºæ‹¼æ¥å…ƒéŸ³ï¼ˆç¡®ä¿åŒ…å«ç›®æ ‡å…ƒéŸ³ï¼‰\n",
    "        num_vowels = np.random.randint(\n",
    "            AUGMENT_CONFIG['concat_min_vowels'],\n",
    "            AUGMENT_CONFIG['concat_max_vowels'] + 1\n",
    "        )\n",
    "        \n",
    "        concat_audio, labels = concatenate_vowels(vowel_bank, num_vowels)\n",
    "        \n",
    "        if concat_audio is None:\n",
    "            continue\n",
    "        \n",
    "        # æå–æ ·æœ¬\n",
    "        sample, label = extract_training_sample(concat_audio, labels)\n",
    "        \n",
    "        # åªä¿ç•™ç›®æ ‡å…ƒéŸ³çš„æ ·æœ¬ï¼ˆæˆ–å…è®¸ä¸€å®šæ¯”ä¾‹çš„å…¶ä»–å…ƒéŸ³ä»¥å¢åŠ å¤šæ ·æ€§ï¼‰\n",
    "        if label != target_vowel and np.random.random() > 0.1:\n",
    "            continue\n",
    "        \n",
    "        # éšæœºæ·»åŠ å™ªå£°\n",
    "        if np.random.random() < AUGMENT_CONFIG['noise_prob']:\n",
    "            noise_level = np.random.uniform(*AUGMENT_CONFIG['noise_level_range'])\n",
    "            sample = add_noise(sample, noise_level)\n",
    "        \n",
    "        # å½’ä¸€åŒ–\n",
    "        max_val = np.max(np.abs(sample))\n",
    "        if max_val > 0:\n",
    "            sample = sample / max_val * 0.9\n",
    "        \n",
    "        generated_samples[label].append(sample)\n",
    "        if label == target_vowel:\n",
    "            count += 1\n",
    "\n",
    "# ç”Ÿæˆé™éŸ³æ ·æœ¬\n",
    "print(\"\\nç”Ÿæˆé™éŸ³æ ·æœ¬...\")\n",
    "for _ in range(samples_per_vowel):\n",
    "    silence = generate_silence_sample()\n",
    "    generated_samples['silence'].append(silence)\n",
    "\n",
    "# ç»Ÿè®¡\n",
    "print(\"\\nç”Ÿæˆç»“æœ:\")\n",
    "print(\"-\"*40)\n",
    "total = 0\n",
    "for vowel in VOWEL_CLASSES:\n",
    "    count = len(generated_samples.get(vowel, []))\n",
    "    print(f\"  {vowel}: {count} ä¸ªæ ·æœ¬\")\n",
    "    total += count\n",
    "print(\"-\"*40)\n",
    "print(f\"  æ€»è®¡: {total} ä¸ªæ ·æœ¬\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64457eb",
   "metadata": {},
   "source": [
    "## 6. å®šä¹‰æ¨¡å‹\n",
    "\n",
    "ä¸ TIMIT ç‰ˆæœ¬ç›¸åŒçš„æ¨¡å‹æ¶æ„ï¼ŒåŒ…å« MelSpectrogram å±‚ä»¥ç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä¸€è‡´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947bb669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_mel_filterbank(num_mels=N_MELS, num_spectrogram_bins=FFT_LENGTH // 2 + 1,\n",
    "                          sample_rate=SAMPLE_RATE, lower_freq=0.0, upper_freq=8000.0):\n",
    "    \"\"\"åˆ›å»º Mel æ»¤æ³¢å™¨ç»„çŸ©é˜µ\"\"\"\n",
    "    return tf.signal.linear_to_mel_weight_matrix(\n",
    "        num_mel_bins=num_mels,\n",
    "        num_spectrogram_bins=num_spectrogram_bins,\n",
    "        sample_rate=sample_rate,\n",
    "        lower_edge_hertz=lower_freq,\n",
    "        upper_edge_hertz=upper_freq\n",
    "    ).numpy()\n",
    "\n",
    "\n",
    "class MelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Mel é¢‘è°±æå–å±‚ - å°†åŸå§‹æ³¢å½¢è½¬æ¢ä¸º Log-Mel ç‰¹å¾\n",
    "    è¯¥å±‚ä¼šè¢«å¯¼å‡ºåˆ° TensorFlow.jsï¼Œç¡®ä¿è®­ç»ƒå’Œæ¨ç†ä¸€è‡´\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, frame_length=FRAME_LENGTH, frame_step=FRAME_STEP,\n",
    "                 fft_length=FFT_LENGTH, num_mels=N_MELS,\n",
    "                 sample_rate=SAMPLE_RATE, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        self.fft_length = fft_length\n",
    "        self.num_mels = num_mels\n",
    "        self.sample_rate = sample_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        mel_filterbank = create_mel_filterbank(\n",
    "            num_mels=self.num_mels,\n",
    "            num_spectrogram_bins=self.fft_length // 2 + 1,\n",
    "            sample_rate=self.sample_rate\n",
    "        )\n",
    "        self.mel_filterbank = self.add_weight(\n",
    "            name='mel_filterbank',\n",
    "            shape=mel_filterbank.shape,\n",
    "            initializer=tf.constant_initializer(mel_filterbank),\n",
    "            trainable=False\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, waveform):\n",
    "        # STFT\n",
    "        stft = tf.signal.stft(\n",
    "            waveform,\n",
    "            frame_length=self.frame_length,\n",
    "            frame_step=self.frame_step,\n",
    "            fft_length=self.fft_length,\n",
    "            window_fn=tf.signal.hann_window\n",
    "        )\n",
    "\n",
    "        # å¹…åº¦è°±\n",
    "        magnitude = tf.abs(stft)\n",
    "\n",
    "        # Mel æ»¤æ³¢\n",
    "        mel = tf.matmul(magnitude, self.mel_filterbank)\n",
    "\n",
    "        # å¯¹æ•°å‹ç¼©\n",
    "        log_mel = tf.math.log(mel + 1e-6)\n",
    "\n",
    "        # æ·»åŠ é€šé“ç»´åº¦ [batch, time, mels, 1]\n",
    "        return tf.expand_dims(log_mel, -1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'frame_length': self.frame_length,\n",
    "            'frame_step': self.frame_step,\n",
    "            'fft_length': self.fft_length,\n",
    "            'num_mels': self.num_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def create_vowel_model(include_mel_layer=True):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºå…ƒéŸ³è¯†åˆ«æ¨¡å‹\n",
    "\n",
    "    Args:\n",
    "        include_mel_layer: æ˜¯å¦åŒ…å« Mel ç‰¹å¾æå–å±‚\n",
    "            - True: è¾“å…¥åŸå§‹æ³¢å½¢ï¼Œç”¨äºæœ€ç»ˆå¯¼å‡º\n",
    "            - False: è¾“å…¥é¢„æå–çš„ Mel ç‰¹å¾ï¼Œç”¨äºåŠ é€Ÿè®­ç»ƒ\n",
    "    \"\"\"\n",
    "    num_time_steps = int((INPUT_SAMPLES - FRAME_LENGTH) / FRAME_STEP) + 1\n",
    "\n",
    "    if include_mel_layer:\n",
    "        waveform_input = tf.keras.Input(shape=(INPUT_SAMPLES,), name='waveform')\n",
    "        x = MelSpectrogram(name='mel_spectrogram')(waveform_input)\n",
    "    else:\n",
    "        x = tf.keras.Input(shape=(num_time_steps, N_MELS, 1), name='mel_input')\n",
    "        waveform_input = x\n",
    "\n",
    "    # CNN åˆ†ç±»éƒ¨åˆ†\n",
    "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', name='conv1')(x if include_mel_layer else waveform_input)\n",
    "    x = tf.keras.layers.BatchNormalization(name='bn1')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), name='pool1')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='bn2')(x)\n",
    "    x = tf.keras.layers.MaxPooling2D((2, 2), name='pool2')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', name='conv3')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='bn3')(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name='gap')(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32, activation='relu', name='dense1')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, name='dropout')(x)\n",
    "\n",
    "    output = tf.keras.layers.Dense(NUM_CLASSES, activation='sigmoid', name='vowel_output')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=waveform_input, outputs=output, name='vowel_classifier')\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_full_model_from_weights(feature_model):\n",
    "    \"\"\"ä»è®­ç»ƒå¥½çš„ç‰¹å¾æ¨¡å‹åˆ›å»ºå®Œæ•´æ¨¡å‹ï¼ˆåŒ…å« Mel å±‚ï¼‰\"\"\"\n",
    "    full_model = create_vowel_model(include_mel_layer=True)\n",
    "\n",
    "    for layer in feature_model.layers:\n",
    "        if layer.name in [l.name for l in full_model.layers]:\n",
    "            if layer.name not in ['mel_spectrogram', 'waveform', 'mel_input']:\n",
    "                full_model.get_layer(layer.name).set_weights(layer.get_weights())\n",
    "\n",
    "    return full_model\n",
    "\n",
    "\n",
    "# æµ‹è¯•æ¨¡å‹åˆ›å»º\n",
    "print(\"æµ‹è¯•æ¨¡å‹åˆ›å»º...\")\n",
    "test_model = create_vowel_model(include_mel_layer=True)\n",
    "test_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621cabb7",
   "metadata": {},
   "source": [
    "## 7. å‡†å¤‡è®­ç»ƒæ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def extract_mel_features(audio_batch):\n",
    "    \"\"\"æå– Mel é¢‘è°±ç‰¹å¾\"\"\"\n",
    "    stft = tf.signal.stft(\n",
    "        audio_batch,\n",
    "        frame_length=FRAME_LENGTH,\n",
    "        frame_step=FRAME_STEP,\n",
    "        fft_length=FFT_LENGTH,\n",
    "        window_fn=tf.signal.hann_window\n",
    "    )\n",
    "\n",
    "    magnitude = tf.abs(stft)\n",
    "\n",
    "    mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "        num_mel_bins=N_MELS,\n",
    "        num_spectrogram_bins=FFT_LENGTH // 2 + 1,\n",
    "        sample_rate=SAMPLE_RATE,\n",
    "        lower_edge_hertz=0.0,\n",
    "        upper_edge_hertz=8000.0\n",
    "    )\n",
    "\n",
    "    mel = tf.matmul(magnitude, mel_filterbank)\n",
    "    log_mel = tf.math.log(mel + 1e-6)\n",
    "\n",
    "    return tf.expand_dims(log_mel, -1).numpy()\n",
    "\n",
    "\n",
    "# å‡†å¤‡æ•°æ®\n",
    "print(\"å‡†å¤‡è®­ç»ƒæ•°æ®...\")\n",
    "\n",
    "all_audio = []\n",
    "all_labels = []\n",
    "\n",
    "for vowel_idx, vowel in enumerate(VOWEL_CLASSES):\n",
    "    samples = generated_samples.get(vowel, [])\n",
    "    for sample in samples:\n",
    "        all_audio.append(sample)\n",
    "        all_labels.append(vowel_idx)\n",
    "\n",
    "all_audio = np.array(all_audio, dtype=np.float32)\n",
    "all_labels = np.array(all_labels, dtype=np.int32)\n",
    "\n",
    "print(f\"æ€»æ ·æœ¬æ•°: {len(all_audio)}\")\n",
    "\n",
    "# åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›† (80/10/10)\n",
    "train_audio, temp_audio, train_labels, temp_labels = train_test_split(\n",
    "    all_audio, all_labels, test_size=0.2, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "val_audio, test_audio, val_labels, test_labels = train_test_split(\n",
    "    temp_audio, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"\\næ•°æ®é›†åˆ’åˆ†:\")\n",
    "print(f\"  è®­ç»ƒé›†: {len(train_audio)} æ ·æœ¬\")\n",
    "print(f\"  éªŒè¯é›†: {len(val_audio)} æ ·æœ¬\")\n",
    "print(f\"  æµ‹è¯•é›†: {len(test_audio)} æ ·æœ¬\")\n",
    "\n",
    "# æå– Mel ç‰¹å¾\n",
    "print(\"\\næå– Mel ç‰¹å¾...\")\n",
    "EXTRACT_BATCH_SIZE = 512\n",
    "\n",
    "def batched_mel_extraction(audio_data, batch_size):\n",
    "    if len(audio_data) == 0:\n",
    "        return np.array([])\n",
    "    all_mels = []\n",
    "    for i in range(0, len(audio_data), batch_size):\n",
    "        batch_audio = audio_data[i:i + batch_size]\n",
    "        batch_mel = extract_mel_features(batch_audio)\n",
    "        all_mels.append(batch_mel)\n",
    "    return np.concatenate(all_mels, axis=0)\n",
    "\n",
    "train_mel = batched_mel_extraction(train_audio, EXTRACT_BATCH_SIZE)\n",
    "val_mel = batched_mel_extraction(val_audio, EXTRACT_BATCH_SIZE)\n",
    "test_mel = batched_mel_extraction(test_audio, EXTRACT_BATCH_SIZE)\n",
    "\n",
    "print(f\"\\nMel ç‰¹å¾å½¢çŠ¶:\")\n",
    "print(f\"  è®­ç»ƒé›†: {train_mel.shape}\")\n",
    "print(f\"  éªŒè¯é›†: {val_mel.shape}\")\n",
    "print(f\"  æµ‹è¯•é›†: {test_mel.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f501a1d",
   "metadata": {},
   "source": [
    "## 8. è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8e6bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# è®¡ç®—ç±»åˆ«æƒé‡\n",
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.arange(NUM_CLASSES),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "print(f\"ç±»åˆ«æƒé‡: {class_weight_dict}\")\n",
    "\n",
    "# å°†æ ‡ç­¾è½¬æ¢ä¸º one-hot ç¼–ç ï¼ˆsigmoid + binary_crossentropy éœ€è¦ï¼‰\n",
    "train_labels_onehot = tf.keras.utils.to_categorical(train_labels, NUM_CLASSES)\n",
    "val_labels_onehot = tf.keras.utils.to_categorical(val_labels, NUM_CLASSES)\n",
    "test_labels_onehot = tf.keras.utils.to_categorical(test_labels, NUM_CLASSES)\n",
    "print(f\"æ ‡ç­¾å½¢çŠ¶: {train_labels_onehot.shape}\")\n",
    "\n",
    "# åˆ›å»ºæ¨¡å‹\n",
    "print(\"\\nåˆ›å»ºæ¨¡å‹...\")\n",
    "model = create_vowel_model(include_mel_layer=False)\n",
    "model.summary()\n",
    "\n",
    "# ç¼–è¯‘\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# å›è°ƒ\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=EARLY_STOPPING_PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(CHECKPOINT_DIR, 'best_model.keras'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¼€å§‹è®­ç»ƒ\n",
    "print(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "history = model.fit(\n",
    "    train_mel, train_labels_onehot,\n",
    "    validation_data=(val_mel, val_labels_onehot),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3ea97",
   "metadata": {},
   "source": [
    "## 9. è¯„ä¼°ä¸å¯è§†åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f48d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ç»˜åˆ¶è®­ç»ƒå†å²\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history.history['accuracy'], label='Train')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation')\n",
    "axes[0].set_title('Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history.history['loss'], label='Train')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation')\n",
    "axes[1].set_title('Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'training_history.png'), dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cff3133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# è¯„ä¼°æµ‹è¯•é›†\n",
    "print(\"è¯„ä¼°æµ‹è¯•é›†...\")\n",
    "test_loss, test_acc = model.evaluate(test_mel, test_labels_onehot, verbose=0)\n",
    "print(f\"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f}\")\n",
    "print(f\"æµ‹è¯•é›†æŸå¤±: {test_loss:.4f}\")\n",
    "\n",
    "# é¢„æµ‹\n",
    "predictions = model.predict(test_mel, verbose=0)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# æ··æ·†çŸ©é˜µ\n",
    "cm = confusion_matrix(test_labels, pred_labels)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "ax.set(\n",
    "    xticks=np.arange(NUM_CLASSES),\n",
    "    yticks=np.arange(NUM_CLASSES),\n",
    "    xticklabels=VOWEL_CLASSES,\n",
    "    yticklabels=VOWEL_CLASSES,\n",
    "    title='Confusion Matrix',\n",
    "    ylabel='True',\n",
    "    xlabel='Predicted'\n",
    ")\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(NUM_CLASSES):\n",
    "    for j in range(NUM_CLASSES):\n",
    "        ax.text(j, i, format(cm[i, j], 'd'),\n",
    "               ha=\"center\", va=\"center\",\n",
    "               color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# åˆ†ç±»æŠ¥å‘Š\n",
    "print(\"\\nåˆ†ç±»æŠ¥å‘Š:\")\n",
    "print(classification_report(test_labels, pred_labels, target_names=VOWEL_CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04864a5",
   "metadata": {},
   "source": [
    "## 10. å¯¼å‡ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e74aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå®Œæ•´æ¨¡å‹ï¼ˆåŒ…å« Mel å±‚ï¼‰\n",
    "print(\"åˆ›å»ºå®Œæ•´æ¨¡å‹...\")\n",
    "full_model = create_full_model_from_weights(model)\n",
    "\n",
    "# æµ‹è¯•\n",
    "print(\"\\næµ‹è¯•å®Œæ•´æ¨¡å‹...\")\n",
    "test_input = test_audio[:5]\n",
    "full_output = full_model.predict(test_input, verbose=0)\n",
    "\n",
    "for i in range(5):\n",
    "    true_label = VOWEL_CLASSES[test_labels[i]]\n",
    "    pred_label = VOWEL_CLASSES[np.argmax(full_output[i])]\n",
    "    conf = np.max(full_output[i])\n",
    "    print(f\"  æ ·æœ¬ {i+1}: çœŸå®={true_label}, é¢„æµ‹={pred_label} (ç½®ä¿¡åº¦={conf:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c05876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿å­˜æ¨¡å‹\n",
    "keras_path = os.path.join(OUTPUT_DIR, 'vowel_model.keras')\n",
    "full_model.save(keras_path)\n",
    "print(f\"Keras æ¨¡å‹å·²ä¿å­˜: {keras_path}\")\n",
    "\n",
    "saved_model_path = os.path.join(OUTPUT_DIR, 'saved_model')\n",
    "full_model.export(saved_model_path)\n",
    "print(f\"SavedModel å·²å¯¼å‡º: {saved_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f5d8e",
   "metadata": {},
   "source": [
    "## 11. è½¬æ¢ä¸º TensorFlow.js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e8de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "tfjs_output_path = os.path.join(OUTPUT_DIR, 'tfjs_model')\n",
    "os.makedirs(tfjs_output_path, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    'tensorflowjs_converter',\n",
    "    '--input_format=tf_saved_model',\n",
    "    '--output_format=tfjs_graph_model',\n",
    "    '--quantize_uint8',\n",
    "    '--skip_op_check',\n",
    "    saved_model_path,\n",
    "    tfjs_output_path\n",
    "]\n",
    "\n",
    "print(\"è½¬æ¢ä¸º TensorFlow.js...\")\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"\\nâœ… è½¬æ¢æˆåŠŸ!\")\n",
    "    print(\"\\nè¾“å‡ºæ–‡ä»¶:\")\n",
    "    total_size = 0\n",
    "    for f in os.listdir(tfjs_output_path):\n",
    "        fpath = os.path.join(tfjs_output_path, f)\n",
    "        size = os.path.getsize(fpath)\n",
    "        total_size += size\n",
    "        print(f\"  {f}: {size / 1024:.1f} KB\")\n",
    "    print(f\"\\næ€»å¤§å°: {total_size / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(f\"\\nâŒ è½¬æ¢å¤±è´¥!\")\n",
    "    print(f\"é”™è¯¯: {result.stderr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a20e9c4",
   "metadata": {},
   "source": [
    "## 12. ä¸‹è½½æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb60e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "# æ‰“åŒ…ä¸‹è½½\n",
    "zip_path = '/content/tfjs_model_hillenbrand.zip'\n",
    "shutil.make_archive('/content/tfjs_model_hillenbrand', 'zip', tfjs_output_path)\n",
    "\n",
    "print(f\"æ¨¡å‹å·²æ‰“åŒ…: {zip_path}\")\n",
    "print(f\"å¤§å°: {os.path.getsize(zip_path) / 1024:.1f} KB\")\n",
    "\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤‡ä»½åˆ° Google Drive\n",
    "drive_output = '/content/drive/MyDrive/vowel_model_hillenbrand'\n",
    "os.makedirs(drive_output, exist_ok=True)\n",
    "\n",
    "shutil.copytree(OUTPUT_DIR, os.path.join(drive_output, 'output'), dirs_exist_ok=True)\n",
    "\n",
    "print(f\"\\nâœ… æ‰€æœ‰è¾“å‡ºå·²ä¿å­˜åˆ° Google Drive:\")\n",
    "print(f\"   {drive_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c4965",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ å®Œæˆ!\n",
    "\n",
    "ä½¿ç”¨ Dataset of Vowels è®­ç»ƒçš„æ¨¡å‹åº”è¯¥åœ¨çº¯å…ƒéŸ³è¾“å…¥åœºæ™¯ä¸‹è¡¨ç°æ›´å¥½ã€‚\n",
    "\n",
    "### ä¸ TIMIT ç‰ˆæœ¬çš„å…³é”®åŒºåˆ«\n",
    "\n",
    "| ç‰¹æ€§ | TIMIT | Dataset of Vowels |\n",
    "|------|-------|-------------------|\n",
    "| å…ƒéŸ³ç±»å‹ | åµŒå…¥åœ¨è¯ä¸­ (è¾…éŸ³-å…ƒéŸ³-è¾…éŸ³) | å­¤ç«‹å…ƒéŸ³å½•éŸ³ |\n",
    "| æ•°æ®é¢„å¤„ç† | æ—  | èƒ½é‡æ£€æµ‹ + æœ‰æ•ˆåŒºåŸŸæˆªå– + éŸ³é‡å½’ä¸€åŒ– |\n",
    "| æ•°æ®å¢å¼º | æ—  | å…ƒéŸ³æ‹¼æ¥ + å™ªå£°å åŠ  |\n",
    "| é€‚ç”¨åœºæ™¯ | è¿ç»­è¯­éŸ³è¯†åˆ« | çº¯å…ƒéŸ³/æ­Œå”±è¯†åˆ« |\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "1. å°†ä¸‹è½½çš„æ¨¡å‹æ›¿æ¢ `public/models/vowel/` ä¸­çš„æ–‡ä»¶\n",
    "2. åœ¨ `/debug-ml` é¡µé¢æµ‹è¯•çœŸå®å½•éŸ³æ•ˆæœ\n",
    "3. å¦‚æœæ•ˆæœä»ä¸ç†æƒ³ï¼Œå¯ä»¥å°è¯•ï¼š\n",
    "   - è°ƒæ•´ `PREPROCESS_CONFIG` ä¸­çš„èƒ½é‡é˜ˆå€¼\n",
    "   - è°ƒæ•´ `AUGMENT_CONFIG` å‚æ•°\n",
    "   - å¢åŠ æ›´å¤šå™ªå£°ç±»å‹\n",
    "   - æ·»åŠ æ··å“å¢å¼º"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
